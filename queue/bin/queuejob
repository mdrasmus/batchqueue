#!/usr/bin/env python

from collections import defaultdict
import json
import optparse
import os
import shutil
from subprocess import call
from subprocess import check_call
from subprocess import Popen
from subprocess import PIPE
import sys
import tempfile
import time

# config
CURRENT_JOBS_CMD = "true"
WHOAMI_CMD =  "whoami"
POLL_RATE = 60 # seconds
JOB_SUBMIT = "/bin/bash"
JOBDIR = os.environ.get("JOBS_DIR",
                         os.path.join(os.environ["HOME"], "jobs"))

config = {'current_jobs_cmd': CURRENT_JOBS_CMD,
          'whoami_cmd': WHOAMI_CMD,
          'poll_rate': POLL_RATE,
          'job_submit_cmd': JOB_SUBMIT,
          'jobdir': JOBDIR}

o = optparse.OptionParser()
o.add_option("--nostdin", action="store_true", default=False)
o.add_option("-r", "--run", action="store_true")
o.add_option("-l", "--list", action="store_true",
             help="list jobs for grouping")
o.add_option("-c", "--clear", action="store_true")
#o.add_option("", "--clear-done", action="store_true")
o.add_option("-G", "--groupjobs", action="store_true")
o.add_option("-g", "--groupname")
o.add_option("-s", "--groupsize", default=16, type="int")
o.add_option("-d", "--dir", metavar="jobs_directory")
o.add_option("-j", "--maxjobs", metavar="maximum_jobs_running",
             type="int", default=30)

conf, args = o.parse_args()


#=============================================================================
# shell functions


def doublequote(text):
    """Wrap argument in doublequotes with propper escaping."""
    return '"' + text.replace("\\", "\\\\").replace('"', '\\"').replace("$", "\\$") + '"'


def make_cmdstr(cmd):
    """
    Make a command string with proper argument quoting.
    """
    return " ".join(doublequote(x) for x in cmd)


def unique_eof(input_data):
    """
    Find an End-of-file token not found within lines.
    """
    if "EOF" not in input_data:
        return "EOF"

    i = 2
    while True:
        eof = "EOF%d" % i
        if eof not in input_data:
            return eof
        i += 1


#=============================================================================
# Job queue


class JobQueue(object):
    def __init__(self, jobdir='jobs',
                 job_submit_cmd='/bin/bash',
                 whoami_cmd='whoami',
                 poll_rate=60,
                 max_jobs=50,
                 current_jobs_cmd='',
                 init_dirs=True):
        self._jobdir = jobdir
        self._job_submit_cmd = job_submit_cmd
        self._whoami_cmd = whoami_cmd
        self._current_jobs_cmd = current_jobs_cmd
        self._poll_rate = poll_rate
        self._max_jobs = max_jobs

        # setup directories
        self._donedir = os.path.join(self._jobdir, "done")
        self._subjobsdir = os.path.join(self._jobdir, "subjobs")

        if init_dirs:
            self.init_dirs()


    def init_dirs(self):
        """Create job directories."""
        if not os.path.exists(self._donedir):
            os.mkdir(self._donedir)
        if not os.path.exists(self._subjobsdir):
            os.mkdir(self._subjobsdir)


    def get_running_num_jobs(self):
        """Return the number of jobs currently running."""
        user = os.popen(self._whoami_cmd).read().strip()

        try:
            s = Popen(self._current_jobs_cmd, stdout=PIPE)
            njobs = 0
            for line in s.stdout:
                if user in line:
                    njobs += 1
            return njobs
        except:
            raise Exception("cant get number of jobs right now")


    def get_waiting_jobs(self):
        """Return all jobs in queue."""
        jobs = []
        for x in os.listdir(self._jobdir):
            fn = os.path.join(self._jobdir, x)
            if os.path.isfile(fn):
                jobs.append(fn)
        jobs.sort()
        return jobs


    def remove_job(self, jobfile):
        """Remove a jobfile from the queue."""
        shutil.move(jobfile, self._donedir)


    def submit_job(self, jobfile):
        """Submit a jobfile."""
        call([self._job_submit_cmd, jobfile])


    def _read_job(self, jobfile):
        """Read a job file."""
        job = json.loads(open(jobfile).read())
        job["file"] = jobfile
        return job


    def _write_job(self, out, cmd, input_data=None, cwd=None):
        """Write a job to a stream."""
        cmdstr = make_cmdstr(cmd)

        # Add HERE-DOC if input is given
        if input_data:
            eof = unique_eof(input_data)
            cmdstr += " <<\"" + eof + "\"\n" + \
                 input_data + "\n" + eof

        if cwd is None:
            cwd = os.getcwd()

        out.write("# submitted: %s\n" % time.strftime("%Y/%m/%d %H:%M:%S"))
        out.write("cd %s\n" % doublequote(cwd))
        out.write(cmdstr)


    def queue_job(self, cmd, input_data, cwd=None):
        """
        Queue a command with input.
        """
        prefix = time.strftime("%Y%m%d_%H%M%S_")
        fd, filename = tempfile.mkstemp(".sh", prefix, self._jobdir)
        with os.fdopen(fd, "w") as out:
            self._write_job(out, cmd, input_data, cwd=cwd)
        return filename


    def _get_subjob_files(self):
        """
        Get all group jobs.
        """
        files = [os.path.join(self._subjobsdir, x)
                 for x in os.listdir(self._subjobsdir)]
        files.sort()
        return files


    def get_subjobs(self):
        """
        Read all group jobs.
        """
        return [self._read_job(x)
                for x in self._get_subjob_files()]


    def _make_group_input(self, inputs):
        """
        Make group job commands.
        """
        group_input = "_pid=\n"
        group_input += "".join("(\n" + job_input + "\n) & \n_pid=\"$_pid \"$!\n"
                              for job_input in inputs)
        group_input += "for p in $_pid; do wait $p; done"
        return group_input


    def queue_subjob(self, group_name, size, cmd, input_data):
        """
        Queue a subjob.
        """
        text = json.dumps({"group": group_name,
                           "size": size,
                           "cmd": cmd,
                           "cwd": os.getcwd(),
                           "time": time.strftime("%Y/%m/%d %H:%M:%S"),
                           "input": input_data})

        prefix = time.strftime("%Y%m%d_%H%M%S_")
        fd, filename = tempfile.mkstemp(".json", prefix, self._subjobsdir)
        os.write(fd, text)
        os.close(fd)
        return filename


    def queue_group(self, jobs):
        """Bundle jobs into group and queue group"""

        cmd = jobs[0]["cmd"]
        inputs = [j["input"] for j in jobs]

        group_input = self._make_group_input(inputs)
        groupjob = self.queue_job(cmd, group_input, cwd=jobs[0]["cwd"])

        print
        print "create group %s (%d)" % (jobs[0]["group"], jobs[0]["size"])
        print "  group job:", os.path.basename(groupjob)
        for job in jobs:
            print "  subjob:", job["file"]

        for job in jobs:
            self.remove_job(job["file"])

    #-----------------------
    # actions


    def clear_jobs(self):
        """Clear all jobs from queue."""
        for jobfile in self.get_waiting_jobs():
            self.remove_job(jobfile)


    def queue_groups(self):
        """Create groups out of all jobs waiting for grouping"""

        # cluster into groups
        groups = defaultdict(lambda: [])
        jobs = [x for x in self.get_subjobs()]
        for job in jobs:
            groups[job["group"]].append(job)

        # queue each group
        for group, group_jobs in groups.items():
            group_size = group_jobs[0]["size"]
            for i in range(0, len(jobs), group_size):
                self.queue_group(jobs[i:i+group_size])


    def run_queue(self, maxjobs=None):
        """Poll job queue to create groups and submit jobs"""

        if not maxjobs:
            maxjobs = self._max_jobs

        while True:
            # queue groups
            self.queue_groups()

            print
            print "check queue", time.strftime("%Y/%m/%d %H:%M:%S")

            # determine jobs
            jobs = self.get_waiting_jobs()
            try:
                ncurrent = self.get_running_num_jobs()
            except:
                print "could not get number of current jobs, sleeping"
                time.sleep(POLL_RATE)
                continue

            nsubmit = min(len(jobs), max(maxjobs - ncurrent, 0))

            print "max jobs:", maxjobs
            print "running: ", ncurrent
            print "waiting: ", len(jobs)

            # submit jobs
            for i in range(nsubmit):
                print
                print "> submit %d:" % (i+1), os.path.basename(jobs[i])
                self.submit_job(jobs[i])
                self.remove_job(jobs[i])

            time.sleep(POLL_RATE)


#=============================================================================

# setup config
if conf.dir:
    config['jobdir'] = conf.dir
config['max_jobs'] = conf.maxjobs


# ensure job directories are present
if not os.path.exists(config['jobdir']):
    print >>sys.stderr, "ERROR: jobs directory '%s' does not exist. Please create it." % config['jobdir']
    print >>sys.stderr, "  mkdir %s" % config['jobdir']
    sys.exit(1)


# setup queue
jobqueue = JobQueue(**config)


# Process actions.
if conf.groupjobs:
    # only group jobs
    jobqueue.queue_groups()
    sys.exit(0)

elif conf.run:
    # start queue process
    jobqueue.run_queue()
    sys.exit(0)

elif conf.list:
    # list subjobs
    for i, job in enumerate(jobqueue.get_waiting_jobs()):
        print "\t".join(["job", str(i+1), job])
    for i, job in enumerate(jobqueue.get_subjobs()):
        print "\t".join(map(str, ["subjob", i+1, job["group"],
                                  job.get("time", "")]))
    sys.exit(0)

elif conf.clear:
    jobqueue.clear_jobs()
    print 'all jobs cleared'
    sys.exit(0)


# get command and input
cmd = args
if not conf.nostdin:
    input_data = sys.stdin.read()
else:
    input_data = ''


if not conf.groupname:
    # make simple job
    jobqueue.queue_job(cmd, input_data)
else:
    jobqueue.queue_subjob(conf.groupname, conf.groupsize, cmd, input_data)
